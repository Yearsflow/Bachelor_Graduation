{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>台媒 预测 周 冬雨 金马奖 封后 ， 大气 的 倪妮 却 佳作 难 出</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>food</td>\n",
       "      <td>农村 就是 好 ， 能 吃 到 纯天然 无 添加 的 野生 蜂蜜 ， 营养 又 健康</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fashion</td>\n",
       "      <td>14 款 知性美 装 ， 时尚 惊艳 搁浅 的 阳光 轻熟 的 优雅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>history</td>\n",
       "      <td>火焰喷射器 1000 度 火焰 烧死 鬼子 4 连 拍</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>society</td>\n",
       "      <td>18 岁 青年 砍死 88 岁 老兵</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                        text\n",
       "0  entertainment        台媒 预测 周 冬雨 金马奖 封后 ， 大气 的 倪妮 却 佳作 难 出\n",
       "1           food  农村 就是 好 ， 能 吃 到 纯天然 无 添加 的 野生 蜂蜜 ， 营养 又 健康\n",
       "2        fashion          14 款 知性美 装 ， 时尚 惊艳 搁浅 的 阳光 轻熟 的 优雅\n",
       "3        history                 火焰喷射器 1000 度 火焰 烧死 鬼子 4 连 拍\n",
       "4        society                          18 岁 青年 砍死 88 岁 老兵"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_train=pd.read_csv('./data/train.txt',sep='\\t',names=['label','text'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>history</td>\n",
       "      <td>跟 日本 刀 、 大马士革 剑 、 阿拉伯 弯刀 比 ， 中国 冷兵器 凭 啥 脱颖而出 ？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finance</td>\n",
       "      <td>世界 物 联网 大会 明日 在 京 召开 龙头股 启动 在 即</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>essay</td>\n",
       "      <td>短短 4 句 话 ， 度 了 无数 人</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>郭晶晶 曾 撮合 吴敏霞 与 章子怡 前男友 ， 拒绝 豪门 平淡 才 是 真</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>岁月 这 把 杀猪刀 怎么 就 对 周迅 格外 凶残 呢 ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                            text\n",
       "0        history  跟 日本 刀 、 大马士革 剑 、 阿拉伯 弯刀 比 ， 中国 冷兵器 凭 啥 脱颖而出 ？\n",
       "1        finance                 世界 物 联网 大会 明日 在 京 召开 龙头股 启动 在 即\n",
       "2          essay                             短短 4 句 话 ， 度 了 无数 人\n",
       "3         sports         郭晶晶 曾 撮合 吴敏霞 与 章子怡 前男友 ， 拒绝 豪门 平淡 才 是 真\n",
       "4  entertainment                  岁月 这 把 杀猪刀 怎么 就 对 周迅 格外 凶残 呢 ?"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev=pd.read_csv('./data/dev.txt',sep='\\t',names=['label','text'])\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baby</td>\n",
       "      <td>生完 小孩 ， 公公 伺候 我 坐月子 ， 很 羞涩 很 感动</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fashion</td>\n",
       "      <td>唐艺昕 与 陈伟霆 为 初秋 的 情侣 做出 了 典范 ， 看 他们 如何 穿 情侣 衣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>同学聚会 美女 被 嘲笑 是 剩女 ， 当超帅 老公 带 着 儿子 出场 ， 全场 沸腾 了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finance</td>\n",
       "      <td>中国 供给 侧 至少 存在 六大 问题</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>world</td>\n",
       "      <td>2.5 万英镑 可住 戴妃 闺房</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                            text\n",
       "0           baby                 生完 小孩 ， 公公 伺候 我 坐月子 ， 很 羞涩 很 感动\n",
       "1        fashion    唐艺昕 与 陈伟霆 为 初秋 的 情侣 做出 了 典范 ， 看 他们 如何 穿 情侣 衣\n",
       "2  entertainment  同学聚会 美女 被 嘲笑 是 剩女 ， 当超帅 老公 带 着 儿子 出场 ， 全场 沸腾 了\n",
       "3        finance                             中国 供给 侧 至少 存在 六大 问题\n",
       "4          world                                2.5 万英镑 可住 戴妃 闺房"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test=pd.read_csv('./data/test_with_label.word',sep='\\t',names=['label','text'])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_X=df_train.sample(frac=1).reset_index(drop=True)\n",
    "train_X=df_train\n",
    "train_Y=train_X['label']\n",
    "train_X=train_X['text']\n",
    "#dev_X=df_dev.sample(frac=1).reset_index(drop=True)\n",
    "dev_X=df_dev\n",
    "dev_Y=dev_X['label']\n",
    "dev_X=dev_X['text']\n",
    "#test_X=df_test.sample(frac=1).reset_index(drop=True)\n",
    "test_X=df_test\n",
    "test_Y=test_X['label']\n",
    "test_X=test_X['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>，</td>\n",
       "      <td>124634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>的</td>\n",
       "      <td>94820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>！</td>\n",
       "      <td>49051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>？</td>\n",
       "      <td>37853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>了</td>\n",
       "      <td>33303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word   times\n",
       "0    ，  124634\n",
       "1    的   94820\n",
       "2    ！   49051\n",
       "3    ？   37853\n",
       "4    了   33303"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "vocab=pd.read_csv('./data/vocab.txt',sep='\\t',names=['word','times'],quoting=csv.QUOTE_NONE)\n",
    "vocab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_Chinese(text): #去除非汉字\n",
    "    words=text.split(' ')\n",
    "    Chinese_txt=''\n",
    "    for word in words:\n",
    "        if word>=u'\\u4e00' and word<=u'\\u9fa5':\n",
    "            Chinese_txt+=word+' '\n",
    "    return Chinese_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1='./data/中文停用词表.txt'\n",
    "file2='./data/哈工大停用词表.txt'\n",
    "file3='./data/四川大学机器智能实验室停用词库.txt'\n",
    "stopwords_set=set()\n",
    "with open(file1,'r',encoding='utf-8') as f1,\\\n",
    "    open(file2,'r',encoding='utf-8') as f2,\\\n",
    "    open(file3,'r',encoding='utf-8') as f3:\n",
    "    for word in f1.readlines():\n",
    "        stopwords_set.add(word.strip())\n",
    "    for word in f2.readlines():\n",
    "        stopwords_set.add(word.strip())\n",
    "    for word in f3.readlines():\n",
    "        stopwords_set.add(word.strip())\n",
    "\n",
    "def remove_stopwords(text): #去除停用词\n",
    "    words=text.split(' ')\n",
    "    Chinese_txt=''\n",
    "    for word in words:\n",
    "        if word not in stopwords_set:\n",
    "            Chinese_txt+=word+' '\n",
    "    return Chinese_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df): #文本清洗\n",
    "    for i in range(len(df)):\n",
    "        df[i]=find_Chinese(df[i])\n",
    "        df[i]=remove_stopwords(df[i])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=clean(train_X)\n",
    "dev_X=clean(dev_X)\n",
    "test_X=clean(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty(df_X,df_Y):\n",
    "    remove_list=[]\n",
    "    for i in range(len(df_X)):\n",
    "        if df_X[i]=='':\n",
    "            remove_list.append(i)\n",
    "    remove_list.reverse()\n",
    "    for i in remove_list:\n",
    "        del df_X[i]\n",
    "        del df_Y[i]\n",
    "    return df_X,df_Y\n",
    "\n",
    "train_X,train_Y=remove_empty(train_X,train_Y)\n",
    "dev_X,dev_Y=remove_empty(dev_X,dev_Y)\n",
    "test_X,test_Y=remove_empty(test_X,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\Graduation\\lib\\site-packages\\bert_serving\\client\\__init__.py:294: UserWarning: some of your sentences have more tokens than \"max_seq_len=128\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  warnings.warn('some of your sentences have more tokens than \"max_seq_len=%d\" set on the server, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vec finished...\n"
     ]
    }
   ],
   "source": [
    "from bert_serving.client import BertClient\n",
    "bc=BertClient()\n",
    "train_X_vec=bc.encode([x for x in train_X])\n",
    "import numpy as np\n",
    "np.savetxt('train_vec.txt',train_X_vec,fmt='%f',delimiter=' ')\n",
    "np.savetxt('train_label.txt',train_Y,fmt='%s')\n",
    "print('train_vec finished...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev_vec finished...\n"
     ]
    }
   ],
   "source": [
    "dev_X_vec=bc.encode([x for x in dev_X])\n",
    "np.savetxt('dev_vec.txt',dev_X_vec,fmt='%f',delimiter=' ')\n",
    "np.savetxt('dev_label.txt',dev_Y,fmt='%s')\n",
    "print('dev_vec finished...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_vec finished...\n"
     ]
    }
   ],
   "source": [
    "test_X_vec=bc.encode([x for x in test_X])\n",
    "np.savetxt('test_vec.txt',test_X_vec,fmt='%f',delimiter=' ')\n",
    "np.savetxt('test_label.txt',test_Y,fmt='%s')\n",
    "print('test_vec finished...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb765c3868d9bad005e70532223c561422f02f67a5fc37903f253e3d1fb0edf2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('Graduation': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
