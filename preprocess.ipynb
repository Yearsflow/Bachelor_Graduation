{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>台媒 预测 周 冬雨 金马奖 封后 ， 大气 的 倪妮 却 佳作 难 出</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>food</td>\n",
       "      <td>农村 就是 好 ， 能 吃 到 纯天然 无 添加 的 野生 蜂蜜 ， 营养 又 健康</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fashion</td>\n",
       "      <td>14 款 知性美 装 ， 时尚 惊艳 搁浅 的 阳光 轻熟 的 优雅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>history</td>\n",
       "      <td>火焰喷射器 1000 度 火焰 烧死 鬼子 4 连 拍</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>society</td>\n",
       "      <td>18 岁 青年 砍死 88 岁 老兵</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                        text\n",
       "0  entertainment        台媒 预测 周 冬雨 金马奖 封后 ， 大气 的 倪妮 却 佳作 难 出\n",
       "1           food  农村 就是 好 ， 能 吃 到 纯天然 无 添加 的 野生 蜂蜜 ， 营养 又 健康\n",
       "2        fashion          14 款 知性美 装 ， 时尚 惊艳 搁浅 的 阳光 轻熟 的 优雅\n",
       "3        history                 火焰喷射器 1000 度 火焰 烧死 鬼子 4 连 拍\n",
       "4        society                          18 岁 青年 砍死 88 岁 老兵"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_train=pd.read_csv('./data/train.txt',sep='\\t',names=['label','text'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>history</td>\n",
       "      <td>跟 日本 刀 、 大马士革 剑 、 阿拉伯 弯刀 比 ， 中国 冷兵器 凭 啥 脱颖而出 ？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finance</td>\n",
       "      <td>世界 物 联网 大会 明日 在 京 召开 龙头股 启动 在 即</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>essay</td>\n",
       "      <td>短短 4 句 话 ， 度 了 无数 人</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>郭晶晶 曾 撮合 吴敏霞 与 章子怡 前男友 ， 拒绝 豪门 平淡 才 是 真</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>岁月 这 把 杀猪刀 怎么 就 对 周迅 格外 凶残 呢 ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                            text\n",
       "0        history  跟 日本 刀 、 大马士革 剑 、 阿拉伯 弯刀 比 ， 中国 冷兵器 凭 啥 脱颖而出 ？\n",
       "1        finance                 世界 物 联网 大会 明日 在 京 召开 龙头股 启动 在 即\n",
       "2          essay                             短短 4 句 话 ， 度 了 无数 人\n",
       "3         sports         郭晶晶 曾 撮合 吴敏霞 与 章子怡 前男友 ， 拒绝 豪门 平淡 才 是 真\n",
       "4  entertainment                  岁月 这 把 杀猪刀 怎么 就 对 周迅 格外 凶残 呢 ?"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev=pd.read_csv('./data/dev.txt',sep='\\t',names=['label','text'])\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baby</td>\n",
       "      <td>生完 小孩 ， 公公 伺候 我 坐月子 ， 很 羞涩 很 感动</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fashion</td>\n",
       "      <td>唐艺昕 与 陈伟霆 为 初秋 的 情侣 做出 了 典范 ， 看 他们 如何 穿 情侣 衣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>同学聚会 美女 被 嘲笑 是 剩女 ， 当超帅 老公 带 着 儿子 出场 ， 全场 沸腾 了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finance</td>\n",
       "      <td>中国 供给 侧 至少 存在 六大 问题</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>world</td>\n",
       "      <td>2.5 万英镑 可住 戴妃 闺房</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                            text\n",
       "0           baby                 生完 小孩 ， 公公 伺候 我 坐月子 ， 很 羞涩 很 感动\n",
       "1        fashion    唐艺昕 与 陈伟霆 为 初秋 的 情侣 做出 了 典范 ， 看 他们 如何 穿 情侣 衣\n",
       "2  entertainment  同学聚会 美女 被 嘲笑 是 剩女 ， 当超帅 老公 带 着 儿子 出场 ， 全场 沸腾 了\n",
       "3        finance                             中国 供给 侧 至少 存在 六大 问题\n",
       "4          world                                2.5 万英镑 可住 戴妃 闺房"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test=pd.read_csv('./data/test_with_label.word',sep='\\t',names=['label','text'])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_X=df_train.sample(frac=1).reset_index(drop=True)\n",
    "train_X=df_train\n",
    "train_Y=train_X['label']\n",
    "train_X=train_X['text']\n",
    "#dev_X=df_dev.sample(frac=1).reset_index(drop=True)\n",
    "dev_X=df_dev\n",
    "dev_Y=dev_X['label']\n",
    "dev_X=dev_X['text']\n",
    "#test_X=df_test.sample(frac=1).reset_index(drop=True)\n",
    "test_X=df_test\n",
    "test_Y=test_X['label']\n",
    "test_X=test_X['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_Chinese(text): #去除非汉字\n",
    "    words=text.split(' ')\n",
    "    Chinese_txt=''\n",
    "    for word in words:\n",
    "        if word>=u'\\u4e00' and word<=u'\\u9fa5':\n",
    "            Chinese_txt+=word+' '\n",
    "    return Chinese_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1='./data/中文停用词表.txt'\n",
    "file2='./data/哈工大停用词表.txt'\n",
    "file3='./data/四川大学机器智能实验室停用词库.txt'\n",
    "stopwords_set=set()\n",
    "with open(file1,'r',encoding='utf-8') as f1,\\\n",
    "    open(file2,'r',encoding='utf-8') as f2,\\\n",
    "    open(file3,'r',encoding='utf-8') as f3:\n",
    "    for word in f1.readlines():\n",
    "        stopwords_set.add(word.strip())\n",
    "    for word in f2.readlines():\n",
    "        stopwords_set.add(word.strip())\n",
    "    for word in f3.readlines():\n",
    "        stopwords_set.add(word.strip())\n",
    "\n",
    "def remove_stopwords(text): #去除停用词\n",
    "    words=text.split(' ')\n",
    "    Chinese_txt=''\n",
    "    for word in words:\n",
    "        if word not in stopwords_set:\n",
    "            Chinese_txt+=word+' '\n",
    "    return Chinese_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df): #文本清洗\n",
    "    for i in range(len(df)):\n",
    "        df[i]=find_Chinese(df[i])\n",
    "        df[i]=remove_stopwords(df[i])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=clean(train_X)\n",
    "dev_X=clean(dev_X)\n",
    "test_X=clean(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty(df_X,df_Y):\n",
    "    remove_list=[]\n",
    "    for i in range(len(df_X)):\n",
    "        if df_X[i]=='':\n",
    "            remove_list.append(i)\n",
    "    remove_list.reverse()\n",
    "    for i in remove_list:\n",
    "        del df_X[i]\n",
    "        del df_Y[i]\n",
    "    return df_X,df_Y\n",
    "\n",
    "train_X,train_Y=remove_empty(train_X,train_Y)\n",
    "dev_X,dev_Y=remove_empty(dev_X,dev_Y)\n",
    "test_X,test_Y=remove_empty(test_X,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155746,)\n",
      "(35011,)\n",
      "(35968,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(dev_X.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(os.getcwd()+'\\\\model'):\n",
    "    os.mkdir(os.getcwd()+'\\\\model')\n",
    "    os.chdir(os.getcwd()+'\\\\model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many words: 135901\n",
      "tf-idf shape: (226725,135901)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer=CountVectorizer()\n",
    "transformer=TfidfTransformer()\n",
    "corpus=train_X.tolist()+dev_X.tolist()+test_X.tolist()\n",
    "tfidf=transformer.fit_transform(vectorizer.fit_transform(corpus))\n",
    "import joblib\n",
    "joblib.dump(transformer,'TfidfTransformer.pkl')\n",
    "joblib.dump(vectorizer,'CountVectorizer.pkl')\n",
    "words=vectorizer.get_feature_names_out()\n",
    "print('how many words: {0}'.format(len(words)))\n",
    "print('tf-idf shape: ({0},{1})'.format(tfidf.shape[0],tfidf.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "encoder=preprocessing.LabelEncoder()\n",
    "corpus_label=train_Y.tolist()+dev_Y.tolist()+test_Y.tolist()\n",
    "corpus_encode_label=encoder.fit_transform(corpus_label)\n",
    "train_label=corpus_encode_label[:train_X.shape[0]]\n",
    "dev_label=corpus_encode_label[train_X.shape[0]:train_X.shape[0]+dev_X.shape[0]]\n",
    "test_label=corpus_encode_label[train_X.shape[0]+dev_X.shape[0]:]\n",
    "train_set=tfidf[:train_X.shape[0]]\n",
    "dev_set=tfidf[train_X.shape[0]:train_X.shape[0]+dev_X.shape[0]]\n",
    "test_set=tfidf[train_X.shape[0]+dev_X.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val mean accuracy: 0.7397389391905401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84      1998\n",
      "           1       0.85      0.81      0.83      1997\n",
      "           2       0.94      0.74      0.83      2000\n",
      "           3       0.62      0.74      0.68      1999\n",
      "           4       0.86      0.57      0.68      1994\n",
      "           5       0.73      0.78      0.75      2000\n",
      "           6       0.75      0.76      0.75      1998\n",
      "           7       0.73      0.82      0.78      1995\n",
      "           8       0.82      0.80      0.81      1999\n",
      "           9       0.73      0.80      0.76      2000\n",
      "          10       0.78      0.80      0.79      2000\n",
      "          11       0.87      0.63      0.73      1999\n",
      "          12       0.42      0.62      0.50      1998\n",
      "          13       0.82      0.83      0.82      1999\n",
      "          14       0.88      0.55      0.67      1999\n",
      "          15       0.74      0.75      0.74      1997\n",
      "          16       0.63      0.77      0.69      1999\n",
      "          17       0.70      0.67      0.68      1997\n",
      "\n",
      "    accuracy                           0.74     35968\n",
      "   macro avg       0.76      0.74      0.74     35968\n",
      "weighted avg       0.76      0.74      0.74     35968\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DCrusher\\.conda\\envs\\Graduation\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "lr_model=LogisticRegression()\n",
    "lr_model.fit(train_set,train_label)\n",
    "print('val mean accuracy: {0}'.format(lr_model.score(dev_set,dev_label)))\n",
    "y_pred=lr_model.predict(test_set)\n",
    "print(classification_report(test_label,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val mean accuracy: 0.6817285995829881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.87      0.79      1998\n",
      "           1       0.78      0.76      0.77      1997\n",
      "           2       0.86      0.77      0.81      2000\n",
      "           3       0.64      0.60      0.62      1999\n",
      "           4       0.52      0.75      0.61      1994\n",
      "           5       0.63      0.71      0.67      2000\n",
      "           6       0.68      0.70      0.69      1998\n",
      "           7       0.65      0.75      0.70      1995\n",
      "           8       0.75      0.74      0.74      1999\n",
      "           9       0.72      0.69      0.70      2000\n",
      "          10       0.74      0.72      0.73      2000\n",
      "          11       0.77      0.58      0.66      1999\n",
      "          12       0.46      0.45      0.45      1998\n",
      "          13       0.82      0.72      0.77      1999\n",
      "          14       0.82      0.49      0.61      1999\n",
      "          15       0.67      0.68      0.67      1997\n",
      "          16       0.58      0.66      0.62      1999\n",
      "          17       0.61      0.59      0.60      1997\n",
      "\n",
      "    accuracy                           0.68     35968\n",
      "   macro avg       0.69      0.68      0.68     35968\n",
      "weighted avg       0.69      0.68      0.68     35968\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model=RandomForestClassifier()\n",
    "rf_model.fit(train_set,train_label)\n",
    "print('val mean accuracy: {0}'.format(rf_model.score(dev_set,dev_label)))\n",
    "y_pred=rf_model.predict(test_set)\n",
    "print(classification_report(test_label,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RandomForest.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(lr_model,'LogisticRegression.pkl')\n",
    "joblib.dump(rf_model,'RandomForest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val mean accuracy: 0.12019079717802976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.22      0.23      1998\n",
      "           1       0.14      0.14      0.14      1997\n",
      "           2       0.91      0.12      0.21      2000\n",
      "           3       0.58      0.03      0.06      1999\n",
      "           4       0.06      0.81      0.12      1994\n",
      "           5       0.13      0.11      0.12      2000\n",
      "           6       0.30      0.09      0.14      1998\n",
      "           7       0.17      0.16      0.17      1995\n",
      "           8       0.62      0.07      0.12      1999\n",
      "           9       0.80      0.03      0.07      2000\n",
      "          10       0.78      0.02      0.04      2000\n",
      "          11       0.43      0.07      0.12      1999\n",
      "          12       0.15      0.03      0.05      1998\n",
      "          13       0.63      0.01      0.02      1999\n",
      "          14       0.55      0.08      0.14      1999\n",
      "          15       0.22      0.07      0.11      1997\n",
      "          16       0.78      0.07      0.13      1999\n",
      "          17       0.80      0.03      0.05      1997\n",
      "\n",
      "    accuracy                           0.12     35968\n",
      "   macro avg       0.46      0.12      0.11     35968\n",
      "weighted avg       0.46      0.12      0.11     35968\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "kn_model=KNeighborsClassifier()\n",
    "kn_model.fit(train_set,train_label)\n",
    "print('val mean accuracy: {0}'.format(kn_model.score(dev_set,dev_label)))\n",
    "y_pred=kn_model.predict(test_set)\n",
    "print(classification_report(test_label,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val mean accuracy: 0.5944131844277513\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74      1998\n",
      "           1       0.72      0.68      0.70      1997\n",
      "           2       0.81      0.67      0.74      2000\n",
      "           3       0.51      0.51      0.51      1999\n",
      "           4       0.47      0.65      0.54      1994\n",
      "           5       0.56      0.61      0.59      2000\n",
      "           6       0.61      0.62      0.61      1998\n",
      "           7       0.61      0.66      0.63      1995\n",
      "           8       0.68      0.66      0.67      1999\n",
      "           9       0.61      0.62      0.62      2000\n",
      "          10       0.64      0.64      0.64      2000\n",
      "          11       0.68      0.49      0.57      1999\n",
      "          12       0.37      0.39      0.38      1998\n",
      "          13       0.71      0.65      0.68      1999\n",
      "          14       0.72      0.46      0.56      1999\n",
      "          15       0.59      0.61      0.60      1997\n",
      "          16       0.51      0.55      0.53      1999\n",
      "          17       0.50      0.54      0.52      1997\n",
      "\n",
      "    accuracy                           0.60     35968\n",
      "   macro avg       0.61      0.60      0.60     35968\n",
      "weighted avg       0.61      0.60      0.60     35968\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dc_model=DecisionTreeClassifier()\n",
    "dc_model.fit(train_set,train_label)\n",
    "print('val mean accuracy: {0}'.format(dc_model.score(dev_set,dev_label)))\n",
    "y_pred=dc_model.predict(test_set)\n",
    "print(classification_report(test_label,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KNeighborsClassifier.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(dc_model,'DecisionTree.pkl')\n",
    "joblib.dump(kn_model,'KNeighborsClassifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val mean accuracy: 0.22787124046728172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.62      0.69      1998\n",
      "           1       0.79      0.06      0.10      1997\n",
      "           2       0.77      0.52      0.62      2000\n",
      "           3       0.07      0.93      0.13      1999\n",
      "           4       0.88      0.13      0.23      1994\n",
      "           5       0.83      0.07      0.13      2000\n",
      "           6       0.00      0.00      0.00      1998\n",
      "           7       0.94      0.28      0.43      1995\n",
      "           8       0.89      0.32      0.47      1999\n",
      "           9       0.76      0.15      0.26      2000\n",
      "          10       0.43      0.36      0.39      2000\n",
      "          11       0.00      0.00      0.00      1999\n",
      "          12       0.00      0.00      0.00      1998\n",
      "          13       0.00      0.00      0.00      1999\n",
      "          14       0.83      0.27      0.40      1999\n",
      "          15       0.80      0.17      0.29      1997\n",
      "          16       0.78      0.05      0.09      1999\n",
      "          17       0.54      0.16      0.25      1997\n",
      "\n",
      "    accuracy                           0.23     35968\n",
      "   macro avg       0.56      0.23      0.25     35968\n",
      "weighted avg       0.56      0.23      0.25     35968\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DCrusher\\.conda\\envs\\Graduation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\DCrusher\\.conda\\envs\\Graduation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\DCrusher\\.conda\\envs\\Graduation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "ab_model=AdaBoostClassifier()\n",
    "ab_model.fit(train_set,train_label)\n",
    "print('val mean accuracy: {0}'.format(ab_model.score(dev_set,dev_label)))\n",
    "y_pred=ab_model.predict(test_set)\n",
    "print(classification_report(test_label,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AdaBoost.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ab_model,'AdaBoost.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Graduation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1eb8c308f398e8f6ef7ed74fd40623744074a7db519e996eeab05a10f3e9726c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
